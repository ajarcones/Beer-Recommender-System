{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from warnings import catch_warnings, simplefilter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- CARGAREMOS EL DATASET DE ENTRADA DE LAS VALORACIONES PARA EL RECOMENDADOR Y LO DIVIDIREMOS EN DOS DATASETS DE TRAINING Y TEST USANDO ShuffleSplit en vez de Kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews_df(data_root='./Data/', reviews_file_name='beer_reviews_v3.csv',\n",
    "                    columns=['user_id', 'beer_id', 'beeradvocate_score'], verbose=False):\n",
    "    \n",
    "    beer_reviews_file_name = os.path.join(data_root, reviews_file_name)\n",
    "    if verbose:\n",
    "        print(\"BEGIN load_reviews_df reviews LOADING ...\\n\")\n",
    "        print(\"beer_reviews_file_name:\", beer_reviews_file_name)\n",
    "        print(\"columns:\", columns)\n",
    "    reviewsdfAux = pd.read_csv(beer_reviews_file_name, sep=',')\n",
    "    reviewsdf = reviewsdfAux[columns].copy()\n",
    "    return(reviewsdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as_matrix() ESTARA OBSOLETA EN EL FUTURO y se muestra un warning.\n",
    "\n",
    "Aconsejan usar en su lugar una nueva funcion to_numpy() que llegara con pandas v0.24.0.\n",
    "\n",
    "https://stackoverflow.com/questions/13187778/convert-pandas-dataframe-to-numpy-array\n",
    "\n",
    "Como usamos as_matrix() anularemos ese WARNING que ya que nuestra version de pandas es anterior a v0.24.0. \n",
    "\n",
    "En el futuro habria que instalar pandas v0.24.0 y sustituir la llamada a as_matrix() por to_numpy()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(reviewsdf, X_columns_indexes, Y_column_indexes, nfolds=3, verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "            print(X_columns_indexes)\n",
    "            print(Y_column_indexes)\n",
    "    \n",
    "    with catch_warnings():\n",
    "        simplefilter(action='ignore', category=FutureWarning)\n",
    "        X = reviewsdf[X_columns_indexes].as_matrix()\n",
    "        Y = reviewsdf[Y_column_indexes].as_matrix()\n",
    "        \n",
    "    kf = KFold(n_splits=3, random_state=15, shuffle=True)        \n",
    "    if verbose:\n",
    "        print(\"Splitting BEGIN -----------------\")\n",
    "        print(kf)\n",
    "            \n",
    "    c = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        if verbose and c < 20:\n",
    "            c += 1\n",
    "            print(\"Splitting Iteration Counter: {0}, TRAIN_index: {1}, TEST_index: {2}\" \\\n",
    "                  .format(c, train_index, test_index))\n",
    "        elif verbose:\n",
    "            print(\"... and so on\")\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "            \n",
    "    if verbose:\n",
    "            print(\"Splitting END -------------------\")\n",
    "    \n",
    "    return pd.DataFrame(X_train), pd.DataFrame(Y_train), pd.DataFrame(X_test), pd.DataFrame(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dsc/Python_notebooks/TFM-ajao-Beer-Recommender\n"
     ]
    }
   ],
   "source": [
    "cd \"/home/dsc/Python_notebooks/TFM-ajao-Beer-Recommender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN load_reviews_df reviews LOADING ...\n",
      "\n",
      "beer_reviews_file_name: /home/dsc/Python_notebooks/TFM-ajao-Beer-Recommender/Data/beer_reviews_v3.csv\n",
      "columns: ['user_id', 'beer_id', 'beeradvocate_score']\n"
     ]
    }
   ],
   "source": [
    "beeradvocate_df = load_reviews_df(\"/home/dsc/Python_notebooks/TFM-ajao-Beer-Recommender/Data\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>beeradvocate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  beer_id  beeradvocate_score\n",
       "0        0        0                4.37\n",
       "1        1        0                4.24\n",
       "2        2        0                4.37\n",
       "3        3        0                4.03\n",
       "4        4        0                3.29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beeradvocate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1301173 entries, 0 to 1301172\n",
      "Data columns (total 3 columns):\n",
      "user_id               1301173 non-null int64\n",
      "beer_id               1301173 non-null int64\n",
      "beeradvocate_score    1301173 non-null float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 29.8 MB\n"
     ]
    }
   ],
   "source": [
    "beeradvocate_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La division de TRAINING Y TEST la haremos con Kfolds y nfolds=3 ya que es el valor aconsejado para un DATASET GRANDE.\n",
    "\n",
    "https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = split_dataset(beeradvocate_df, \\\n",
    "                                                 beeradvocate_df.columns[:2], beeradvocate_df.columns[2:3], \\\n",
    "                                                 10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  0\n",
       "1  4  0\n",
       "2  5  0\n",
       "3  6  0\n",
       "4  7  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 867449 entries, 0 to 867448\n",
      "Data columns (total 2 columns):\n",
      "0    867449 non-null int64\n",
      "1    867449 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 13.2 MB\n"
     ]
    }
   ],
   "source": [
    "# nfolds=3, 867449 rows\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1\n",
       "0   0  0\n",
       "1   2  0\n",
       "2   3  0\n",
       "3   8  0\n",
       "4  10  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 433724 entries, 0 to 433723\n",
      "Data columns (total 2 columns):\n",
      "0    433724 non-null int64\n",
      "1    433724 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.6 MB\n"
     ]
    }
   ],
   "source": [
    "# nfolds=3, 433724 rows\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obstante, voy a descartar esta estrategia de division porque considero que deja fuera del DATASET DE TRAINING demasiados registros.\n",
    "\n",
    "Voy a usar el metodo de BARAJEO Y DIVISION para controlar el numero de registros de TRAINING Y TEST y obtendre  1040938 registros de TRAINING y 260235 registros de TEST que me parece mejor division para el recomendador.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "\"Random permutations cross-validation a.k.a. Shuffle & Split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(reviewsdf, X_columns_indexes, Y_column_indexes, \\\n",
    "                    n_splits=10, test_size=.20, train_size=0.80, random_state=0, verbose=False):\n",
    "\n",
    "    columns=['user_id', 'beer_id', 'beeradvocate_score']\n",
    "    \n",
    "    if verbose:\n",
    "            print(X_columns_indexes)\n",
    "            print(Y_column_indexes)\n",
    "    \n",
    "    with catch_warnings():\n",
    "        simplefilter(action='ignore', category=FutureWarning)\n",
    "        X = reviewsdf[X_columns_indexes].as_matrix()\n",
    "        Y = reviewsdf[Y_column_indexes].as_matrix()\n",
    "        \n",
    "    rs = ShuffleSplit(n_splits, test_size, train_size, random_state)\n",
    "    if verbose:\n",
    "        print(\"Shuffling BEGIN -----------------\")\n",
    "        print(rs)\n",
    "            \n",
    "    c = 0\n",
    "    for train_index, test_index in rs.split(X):\n",
    "        if verbose and c < 20:\n",
    "            c += 1\n",
    "            print(\"Shuffling Iteration Counter: {0}, TRAIN_index: {1}, TEST_index: {2}\" \\\n",
    "                  .format(c, train_index, test_index))\n",
    "        elif verbose:\n",
    "            print(\"... and so on\")\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    df_train = pd.concat( \\\n",
    "                [pd.DataFrame(X_train).reset_index().drop('index', axis=1), \\\n",
    "                 pd.DataFrame(Y_train).reset_index().drop('index', axis=1)], \\\n",
    "                 axis=1)\n",
    "    df_train.columns = columns\n",
    "                 \n",
    "    df_test = pd.concat( \\\n",
    "                [pd.DataFrame(X_test).reset_index().drop('index', axis=1), \\\n",
    "                 pd.DataFrame(Y_test).reset_index().drop('index', axis=1)], \\\n",
    "                 axis=1)\n",
    "    df_test.columns = columns\n",
    "    \n",
    "    if verbose:\n",
    "            print(\"Shuffling END -------------------\")\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'beer_id'], dtype='object')\n",
      "Index(['beeradvocate_score'], dtype='object')\n",
      "Shuffling BEGIN -----------------\n",
      "ShuffleSplit(n_splits=10, random_state=0, test_size=0.2, train_size=0.8)\n",
      "Shuffling Iteration Counter: 1, TRAIN_index: [ 947413  779311 1254976 ...  963395  117952  305711], TEST_index: [ 952522  789831  112280 ...  191401 1019561  195974]\n",
      "Shuffling Iteration Counter: 2, TRAIN_index: [ 558245   37246 1119166 ...  406722  839194  918450], TEST_index: [ 281767  963376  639701 ...  575958 1271404   71611]\n",
      "Shuffling Iteration Counter: 3, TRAIN_index: [ 396274  633467 1198197 ...  930239  798882 1142006], TEST_index: [ 583665 1080019 1099842 ...   38943  320954  184520]\n",
      "Shuffling Iteration Counter: 4, TRAIN_index: [1152127  480365 1000074 ...  218213 1274826  582283], TEST_index: [1212540  405140 1290765 ...  502205 1071926  689458]\n",
      "Shuffling Iteration Counter: 5, TRAIN_index: [ 656181   32820 1180048 ...  435386  676883  468681], TEST_index: [1059710  577766  861446 ...  554049  428754  837208]\n",
      "Shuffling Iteration Counter: 6, TRAIN_index: [771183 478425 539803 ... 944266 153583 687059], TEST_index: [ 581245 1294264  629309 ...  925716  612307  223299]\n",
      "Shuffling Iteration Counter: 7, TRAIN_index: [214163 950434 853900 ... 431960 311758 482869], TEST_index: [ 669828 1186590 1151470 ...  135462  684154  924799]\n",
      "Shuffling Iteration Counter: 8, TRAIN_index: [  61940   68359  533393 ...   86026 1032412  723012], TEST_index: [1239842 1091407  410734 ...  722304  857846 1157261]\n",
      "Shuffling Iteration Counter: 9, TRAIN_index: [ 141748  878141 1080492 ...  685956  675504  207737], TEST_index: [245355 959362 899756 ... 805364 540982 110040]\n",
      "Shuffling Iteration Counter: 10, TRAIN_index: [699046 384768 977330 ... 157888  90591 841494], TEST_index: [1232620 1030673  443007 ...    2848  853303  905207]\n",
      "Shuffling END -------------------\n"
     ]
    }
   ],
   "source": [
    "reviews_train, reviews_test = shuffle_dataset(beeradvocate_df, \\\n",
    "                                              beeradvocate_df.columns[:2], beeradvocate_df.columns[2:3], \\\n",
    "                                              10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>beeradvocate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4270</td>\n",
       "      <td>1387</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>514</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4463</td>\n",
       "      <td>2777</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2688</td>\n",
       "      <td>355</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2670</td>\n",
       "      <td>223</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  beer_id  beeradvocate_score\n",
       "0     4270     1387                2.74\n",
       "1      285      514                4.32\n",
       "2     4463     2777                3.13\n",
       "3     2688      355                4.00\n",
       "4     2670      223                4.32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1040938 entries, 0 to 1040937\n",
      "Data columns (total 3 columns):\n",
      "user_id               1040938 non-null int64\n",
      "beer_id               1040938 non-null int64\n",
      "beeradvocate_score    1040938 non-null float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 23.8 MB\n"
     ]
    }
   ],
   "source": [
    "reviews_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>beeradvocate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8578</td>\n",
       "      <td>5279</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1305</td>\n",
       "      <td>3129</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1617</td>\n",
       "      <td>640</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975</td>\n",
       "      <td>454</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1802</td>\n",
       "      <td>6224</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  beer_id  beeradvocate_score\n",
       "0     8578     5279                4.65\n",
       "1     1305     3129                4.12\n",
       "2     1617      640                3.67\n",
       "3      975      454                4.42\n",
       "4     1802     6224                4.03"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260235 entries, 0 to 260234\n",
      "Data columns (total 3 columns):\n",
      "user_id               260235 non-null int64\n",
      "beer_id               260235 non-null int64\n",
      "beeradvocate_score    260235 non-null float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "reviews_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- CARGAREMOS LOS DATASETS DE USUARIOS, CERVEZAS Y ESTILOS DE CERVEZAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_dataframe(file_root='./Data/', file_name='beer_reviews_v3.csv', sep_char=',', verbose=False):\n",
    "    \n",
    "    csv_file_name = os.path.join(file_root, file_name)\n",
    "    if verbose:\n",
    "        print(\"BEGIN dataframe LOADING ...\\n\")\n",
    "        print(\"csv_file_name:\", csv_file_name, \"\\n\")\n",
    "    df = pd.read_csv(csv_file_name, sep=sep_char)\n",
    "    if verbose:\n",
    "        print(\"END dataframe LOADING ...\\n\")\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = load_csv_to_dataframe(\"/home/dsc/Python_notebooks/TFM-ajao-Beer-Recommender/Data\", \\\n",
    "                                 \"users_v1.csv\", ',', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_profilename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>zyzygy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ypsifly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>woemad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wnhay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>williamherbert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id review_profilename\n",
       "0        0             zyzygy\n",
       "1        1            ypsifly\n",
       "2        2             woemad\n",
       "3        3              wnhay\n",
       "4        4     williamherbert"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30810 entries, 0 to 30809\n",
      "Data columns (total 2 columns):\n",
      "user_id               30810 non-null int64\n",
      "review_profilename    30810 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 481.5+ KB\n"
     ]
    }
   ],
   "source": [
    "users_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers_df = load_csv_to_dataframe(\"/home/dsc/Python_notebooks/TFM-ajao-Beer-Recommender/Data\", \\\n",
    "                                 \"beers_v1.csv\", ',', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_advocates_style</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>abv_strength</th>\n",
       "      <th>beer_style_ibu_avg</th>\n",
       "      <th>brewery_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stone Old Guardian Barley Wine Style Ale 2006</td>\n",
       "      <td>American Barleywine</td>\n",
       "      <td>11.20</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Stone Brewing Co.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Samuel Adams Brown Ale</td>\n",
       "      <td>English Brown Ale</td>\n",
       "      <td>5.35</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Boston Beer Company (Samuel Adams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hennepin (Farmhouse Saison)</td>\n",
       "      <td>Belgian Saison</td>\n",
       "      <td>7.70</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Brewery Ommegang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Double Bag</td>\n",
       "      <td>German Altbier</td>\n",
       "      <td>7.20</td>\n",
       "      <td>3</td>\n",
       "      <td>37.5</td>\n",
       "      <td>Long Trail Brewing Co.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Berkshire Russian Imperial Stout</td>\n",
       "      <td>Russian Imperial Stout</td>\n",
       "      <td>8.50</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Berkshire Brewing Company Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id                                      beer_name  \\\n",
       "0        0  Stone Old Guardian Barley Wine Style Ale 2006   \n",
       "1        1                         Samuel Adams Brown Ale   \n",
       "2        2                    Hennepin (Farmhouse Saison)   \n",
       "3        3                                     Double Bag   \n",
       "4        4               Berkshire Russian Imperial Stout   \n",
       "\n",
       "     beer_advocates_style  beer_abv  abv_strength  beer_style_ibu_avg  \\\n",
       "0     American Barleywine     11.20             4                80.0   \n",
       "1       English Brown Ale      5.35             2                20.0   \n",
       "2          Belgian Saison      7.70             3                29.0   \n",
       "3          German Altbier      7.20             3                37.5   \n",
       "4  Russian Imperial Stout      8.50             3                70.0   \n",
       "\n",
       "                         brewery_name  \n",
       "0                   Stone Brewing Co.  \n",
       "1  Boston Beer Company (Samuel Adams)  \n",
       "2                    Brewery Ommegang  \n",
       "3              Long Trail Brewing Co.  \n",
       "4      Berkshire Brewing Company Inc.  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6504 entries, 0 to 6503\n",
      "Data columns (total 7 columns):\n",
      "beer_id                 6504 non-null int64\n",
      "beer_name               6504 non-null object\n",
      "beer_advocates_style    6504 non-null object\n",
      "beer_abv                6504 non-null float64\n",
      "abv_strength            6504 non-null int64\n",
      "beer_style_ibu_avg      6504 non-null float64\n",
      "brewery_name            6504 non-null object\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 355.8+ KB\n"
     ]
    }
   ],
   "source": [
    "beers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles_df = load_csv_to_dataframe(\"/home/dsc/Python_notebooks/TFM-ajao-Beer-Recommender/Data\", \\\n",
    "                                 \"beer_styles_v1.csv\", ',', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abv_range</th>\n",
       "      <th>abv_strength</th>\n",
       "      <th>family_name</th>\n",
       "      <th>ibu_range</th>\n",
       "      <th>ibu_strength</th>\n",
       "      <th>style_URL</th>\n",
       "      <th>style_id</th>\n",
       "      <th>style_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.3-7.6%</td>\n",
       "      <td>3</td>\n",
       "      <td>Bocks</td>\n",
       "      <td>20-30</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.beeradvocate.com/beer/styles/32/</td>\n",
       "      <td>0</td>\n",
       "      <td>German Bock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6-7.9%</td>\n",
       "      <td>3</td>\n",
       "      <td>Bocks</td>\n",
       "      <td>17-27</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.beeradvocate.com/beer/styles/35/</td>\n",
       "      <td>1</td>\n",
       "      <td>German Doppelbock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0-14.0%</td>\n",
       "      <td>4</td>\n",
       "      <td>Bocks</td>\n",
       "      <td>25-35</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.beeradvocate.com/beer/styles/36/</td>\n",
       "      <td>2</td>\n",
       "      <td>German Eisbock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.3-8.1%</td>\n",
       "      <td>3</td>\n",
       "      <td>Bocks</td>\n",
       "      <td>20-38</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.beeradvocate.com/beer/styles/33/</td>\n",
       "      <td>3</td>\n",
       "      <td>German Maibock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0-9.5%</td>\n",
       "      <td>3</td>\n",
       "      <td>Bocks</td>\n",
       "      <td>15-35</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.beeradvocate.com/beer/styles/92/</td>\n",
       "      <td>4</td>\n",
       "      <td>German Weizenbock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abv_range  abv_strength family_name ibu_range  ibu_strength  \\\n",
       "0   6.3-7.6%             3       Bocks     20-30             3   \n",
       "1   6.6-7.9%             3       Bocks     17-27             3   \n",
       "2  7.0-14.0%             4       Bocks     25-35             3   \n",
       "3   6.3-8.1%             3       Bocks     20-38             3   \n",
       "4   7.0-9.5%             3       Bocks     15-35             3   \n",
       "\n",
       "                                      style_URL  style_id         style_name  \n",
       "0  https://www.beeradvocate.com/beer/styles/32/         0        German Bock  \n",
       "1  https://www.beeradvocate.com/beer/styles/35/         1  German Doppelbock  \n",
       "2  https://www.beeradvocate.com/beer/styles/36/         2     German Eisbock  \n",
       "3  https://www.beeradvocate.com/beer/styles/33/         3     German Maibock  \n",
       "4  https://www.beeradvocate.com/beer/styles/92/         4  German Weizenbock  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 111 entries, 0 to 110\n",
      "Data columns (total 8 columns):\n",
      "abv_range       111 non-null object\n",
      "abv_strength    111 non-null int64\n",
      "family_name     111 non-null object\n",
      "ibu_range       111 non-null object\n",
      "ibu_strength    111 non-null int64\n",
      "style_URL       111 non-null object\n",
      "style_id        111 non-null int64\n",
      "style_name      111 non-null object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 7.0+ KB\n"
     ]
    }
   ],
   "source": [
    "styles_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beer_summary_by_id(beers_df, styles_df, beer_id):\n",
    "    beer_summary_values = beers_df[beers_df['beer_id'] == beer_id][['beer_name', 'beer_advocates_style']].values.astype(str)[0]\n",
    "    beer_summary = beer_summary_values[0] + ', ' + beer_summary_values[1]\n",
    "    beer_style = styles_df[styles_df['style_name'] == beer_summary_values[1]]['family_name'].values.astype(str)[0]\n",
    "    beer_summary +=  ' (' + beer_style + ')'\n",
    "    return(beer_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stone Old Guardian Barley Wine Style Ale 2006, American Barleywine (Strong Ales)\n",
      "Mahr's Ungespundet-hefetrüb, German Kellerbier Zwickelbier (Pilseners and Pale Lagers)\n",
      "Wexford Irish Cream Ale, American Cream Ale (Hybrid Beers)\n",
      "Sierra Nevada Anniversary Ale (2007-2009), American IPA (India Pale Ales)\n",
      "Samuel Adams Hallertau Imperial Pilsner, American Imperial Pilsner (Pilseners and Pale Lagers)\n",
      "Odd Notion (Summer 08), English Dark Mild Ale (Brown Ales)\n",
      "Leinenkugel's Red, Vienna Lager (Dark Lagers)\n",
      "Hocus Pocus, American Pale Wheat Ale (Wheat Beers)\n",
      "Chimay Première (Red), Belgian Dubbel (Dark Ales)\n",
      "471 IPA, American Imperial IPA (India Pale Ales)\n"
     ]
    }
   ],
   "source": [
    "beer_id_list = range(0, 100, 10)\n",
    "for beer_id in beer_id_list:\n",
    "    print(get_beer_summary_by_id(beers_df, styles_df, beer_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- METRICAS DE EVALUACION DE RECOMENDADORES Y DE SUS RECOMENDACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    \"\"\"\n",
    "    Implementa las dos metricas mas importantes para evaluar Sistemas de Recomendacion:\n",
    "        . Recall\n",
    "        . MAP\n",
    "    \"\"\"\n",
    "    def __init__(self, train_ids, test_ids, recommended_ids):\n",
    "        \n",
    "        self.zipped = list(zip(test_ids, train_ids, recommended_ids))\n",
    "        \n",
    "    def recall_per_user(self, N, test, recommended, train):\n",
    "        if train is not None: \n",
    "            rec_true = []\n",
    "            for r in recommended:\n",
    "                if r not in train:\n",
    "                    rec_true.append(r)\n",
    "            else:\n",
    "                rec_true = recommended   \n",
    "        intersection = len(set(test) & set(rec_true[:N]))\n",
    "        return intersection / float(np.minimum(N, len(test)))\n",
    "       \n",
    "    def recall_at_n(self, topN):\n",
    "        out = []\n",
    "        for k in topN:\n",
    "            recall = np.mean([self.recall_per_user(k, test, recom, train)  for (test, train, recom) in self.zipped])\n",
    "            out.append(recall)\n",
    "            print(\"recall@%s=%.3f\" %(k, recall))\n",
    "        return out\n",
    "                                       \n",
    "    def apk(self, N, test, recommended, train):\n",
    "        if train is not None: \n",
    "            rec_true = []\n",
    "            for r in recommended:\n",
    "                if r not in train:\n",
    "                    rec_true.append(r)\n",
    "        else:\n",
    "            rec_true = recommended    \n",
    "        predicted = rec_true[:N] # top-k predictions\n",
    "\n",
    "        score = 0.0 # This will store the numerator\n",
    "        num_hits = 0.0 # This will store the sum of rel(i)\n",
    "\n",
    "        for i,p in enumerate(predicted):\n",
    "            if p in test and p not in predicted[:i]:\n",
    "                num_hits += 1.0\n",
    "                score += num_hits/(i+1.0)\n",
    "\n",
    "        return score / min(len(test), N)\n",
    "\n",
    "    def map_at_n(self, topN):\n",
    "        out = []\n",
    "        for k in topN:\n",
    "            map_ = np.mean([self.apk(k, test, recom, train)  for (test, train, recom) in self.zipped])\n",
    "            out.append(map_)\n",
    "            print(\"map@%s=%.3f\" %(k, map_))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.- RECOMENDADORES BASADOS EN LA POPULARIDAD (BASELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class popularity_models(object):\n",
    "    \"\"\"\n",
    "    Se implementan los siguientes recomendadores basados en medidas de popularidad (model):\n",
    "        . mostRated: La cerveza que se ha valorado mayor numero de veces (se asumira que es la cerveza que nas se ha bebido)\n",
    "        . positiveRated: La cerveza que tiene valoraciones positivas por encima de un valor limite dado (threshold)\n",
    "        . mean_rate_movies: La cerveza que tiene la valoracion mas alta de media y tiene un numero minimo de valoraciones\n",
    "    \"\"\"\n",
    "    def __init__(self, model, train_df):\n",
    "        self.model_name = model\n",
    "        self.train_df = train_df\n",
    "    \n",
    "    def mostRated(self):\n",
    "        \"\"\"\n",
    "        Recomendador 'La cerveza que se ha valorado mayor numero de veces'\n",
    "        \"\"\"\n",
    "        return self.train_df.groupby('beer_id')['user_id'].count().sort_values(ascending=False)\n",
    "\n",
    "    def positiveRated(self, min_score=4.0):\n",
    "        \"\"\"\n",
    "        Recomendador 'La cerveza que tiene valoraciones positivas por encima de un valor':\n",
    "          beeradvocate_score > min_score\n",
    "        \"\"\"\n",
    "        return self.train_df[self.train_df['beeradvocate_score'] >= min_score].groupby('beer_id')['user_id'].count().sort_values(ascending=False) \n",
    "        \n",
    "    def mean_rate_beers(self, min_scores=50):\n",
    "        \"\"\"\n",
    "        Recomendador 'La cerveza que tiene la valoracion mas alta de media':\n",
    "            Solo se tendran en cuenta ccervezas con mayor numero de valoraciones que min_scores\n",
    "        \"\"\"\n",
    "        listRatedBeers = self.train_df.groupby('beer_id')['beeradvocate_score'].apply(list).reset_index()\n",
    "        filteredListRatedBeers = listRatedBeers[listRatedBeers['beeradvocate_score'].apply(lambda x: len(x) > min_scores)]\n",
    "        meanBeers = filteredListRatedBeers['beeradvocate_score'].apply(lambda x: np.mean(np.array(x))).sort_values(ascending=False)\n",
    "        return meanBeers\n",
    "        \n",
    "    def train(self, min_rating=4.0, min_ratings=50):\n",
    "        \"\"\"\n",
    "        Entrenamiento del Recomendador de Popularidad En Uso (Instanciado)\n",
    "        \"\"\"\n",
    "        if self.model_name == 'mostRated':\n",
    "            self.model = self.mostRated()\n",
    "        elif self.model_name == 'positiveRated':\n",
    "            self.model = self.positiveRated(min_rating)\n",
    "        elif self.model_name == 'mean_rate_movies':\n",
    "            self.model = self.mean_rate_movies(min_ratings)\n",
    "        else:\n",
    "            raise ValueError('%s no existe' % self.model_name)\n",
    "        \n",
    "    def predict(self, top_k, verbose=False):\n",
    "        \"\"\"\n",
    "        Devuelve las primeras top_k recomendaciones del Recomendador de Popularidad En Uso\n",
    "        \"\"\"\n",
    "        return self.model.index.values[:top_k]\n",
    "    \n",
    "    def get_recommended_beers(self, beers_ids, beers_df):\n",
    "        \"\"\"\n",
    "        Dada una lista de ids de cervezas, devuelve una lista la informacion resumida de cada una\n",
    "        \"\"\"\n",
    "        beers_stuff = []\n",
    "        for i, index in enumerate(beers_ids):\n",
    "            id_ = index # id de la cerveza\n",
    "            beers_stuff.append(str(id_) + ' ' + get_beer_summary_by_id(beers_df, styles_df, id_))\n",
    "\n",
    "        return(list(beers_stuff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.- SISTEMA DE RECOMENDACION BASADO EN POPULARIDAD MostRated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beer_id\n",
       "223    2508\n",
       "142    2421\n",
       "12     2311\n",
       "179    2093\n",
       "130    2067\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_mostRated = popularity_models('mostRated', reviews_train)\n",
    "sr_mostRated.train()\n",
    "sr_mostRated.model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([223, 142,  12, 179, 130, 250, 136, 134, 312, 294])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_mostRated.predict(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223 90 Minute IPA, American Imperial IPA (India Pale Ales)\n",
      "142 Old Rasputin Russian Imperial Stout, Russian Imperial Stout (Stouts)\n",
      "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales)\n",
      "179 Arrogant Bastard Ale, American Strong Ale (Strong Ales)\n",
      "130 Stone Ruination IPA, American Imperial IPA (India Pale Ales)\n",
      "250 Two Hearted Ale, American IPA (India Pale Ales)\n",
      "136 Sierra Nevada Pale Ale, American Pale Ale (APA) (Pale Ales)\n",
      "134 Stone IPA (India Pale Ale), American IPA (India Pale Ales)\n",
      "312 Sierra Nevada Bigfoot Barleywine Style Ale, American Barleywine (Strong Ales)\n",
      "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts)\n"
     ]
    }
   ],
   "source": [
    "for recommended_beer in sr_mostRated.get_recommended_beers(sr_mostRated.predict(10), beers_df):\n",
    "    print(recommended_beer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUACION DEL SISTEMA DE RECOMENDACION MODELO MostRated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MEDIDA Recall-----\n",
      "recall@5=0.042\n",
      "recall@10=0.051\n",
      "recall@20=0.077\n",
      "-----MEDIDA Map-----\n",
      "map@5=0.021\n",
      "map@10=0.018\n",
      "map@20=0.017\n"
     ]
    }
   ],
   "source": [
    "topk = [5, 10, 20]\n",
    "trainUsersGrouped = reviews_train.groupby('user_id')['beer_id'].apply(list).reset_index().sort_index()\n",
    "train_ids = trainUsersGrouped['beer_id'].values\n",
    "testUsersGrouped = reviews_test.groupby('user_id')['beer_id'].apply(list).reset_index().sort_index()\n",
    "test_ids = testUsersGrouped['beer_id'].values\n",
    "\n",
    "predictions = trainUsersGrouped['beer_id'].apply(lambda x: sr_mostRated.predict(np.max(topk))).reset_index()\n",
    "predictions_ids = predictions['beer_id'].values\n",
    "m = Metrics(train_ids, test_ids, predictions_ids)\n",
    "print('-----MEDIDA Recall-----')\n",
    "_ = m.recall_at_n(topk)\n",
    "print('-----MEDIDA Map-----')\n",
    "_ = m.map_at_n(topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AHORA EVALUAREMOS TODOS LOS SISTEMAS DE RECOMENDACION BASADOS EN POPULARIDAD.\n",
    "\n",
    "##### Los resultados son bajos para todos pero el que consigue mejores resultados es mostRated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe['user_id', Lista_'beer:id'] que contiene cada user_id y una lista de los beer_id que ha valorado\n",
    "trainUsersGrouped = reviews_train.groupby('user_id')['beer_id'].apply(list).reset_index().sort_index()\n",
    "train_ids = trainUsersGrouped['beer_id'].values\n",
    "testUsersGrouped = reviews_test.groupby('user_id')['beer_id'].apply(list).reset_index().sort_index()\n",
    "test_ids = testUsersGrouped['beer_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "mostRated\n",
      "-----MEDIDA Recall-----\n",
      "recall@5=0.042\n",
      "recall@10=0.051\n",
      "recall@20=0.077\n",
      "recall@50=0.134\n",
      "-----MEDIDA Map-----\n",
      "map@5=0.021\n",
      "map@10=0.018\n",
      "map@20=0.018\n",
      "map@50=0.018\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "positiveRated\n",
      "-----MEDIDA Recall-----\n",
      "recall@5=0.040\n",
      "recall@10=0.053\n",
      "recall@20=0.076\n",
      "recall@50=0.126\n",
      "-----MEDIDA Map-----\n",
      "map@5=0.020\n",
      "map@10=0.018\n",
      "map@20=0.017\n",
      "map@50=0.017\n",
      "-----------------------\n",
      "\n",
      "-----------------------\n",
      "mean_rate_movies\n",
      "-----MEDIDA Recall-----\n",
      "recall@5=0.003\n",
      "recall@10=0.005\n",
      "recall@20=0.013\n",
      "recall@50=0.026\n",
      "-----MEDIDA Map-----\n",
      "map@5=0.001\n",
      "map@10=0.001\n",
      "map@20=0.002\n",
      "map@50=0.002\n",
      "-----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rs_popularity_list = ['mostRated', 'positiveRated', 'mean_rate_beers']\n",
    "topk = [5, 10, 20, 50]\n",
    "for rs_model_name in rs_popularity_list:\n",
    "    rs_popularity = popularity_models(rs_model_name, reviews_train)\n",
    "    rs_popularity.train()\n",
    "    \n",
    "    predictions = trainUsersGrouped['beer_id'].apply(lambda x: rs_popularity.predict(np.max(topk))).reset_index()\n",
    "    predictions_ids = predictions['beer_id'].values\n",
    "    m = Metrics(train_ids, test_ids, predictions_ids)\n",
    "    print('-----------------------')\n",
    "    print(rs_model_name)\n",
    "    print('-----MEDIDA Recall-----')\n",
    "    _ = m.recall_at_n(topk)\n",
    "    print('-----MEDIDA Map-----')\n",
    "    _ = m.map_at_n(topk)\n",
    "    print('-----------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.- RECOMENDADOR BASADO EN MATRIZ DE CO-OCURRENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAS RECOMENDACIONES SE BASAN EN EL GRADO DE SIMILITUD QUIE TIENEN ENTRE SI LOS CERVEZAS.\n",
    "\n",
    "LA RECOMENDACION DE CERVEZA PARA UN USUARIO CONCRETO SE HARA ASI:\n",
    "\n",
    "    1.- Una funcion devolvera los topN cervezas mas similares a una dada:\n",
    "co_occurrance_similarity(item_id, coocurrance, ntop=10) \n",
    "\n",
    "    2. Otra funcion co_occurrance_recommendation(items_id, cooccurrance, ntop=10),\n",
    "para un usuario dado y la lista de cervezas que ha valorado, \n",
    "seleccionaremos las topN cervezas de las listas de cervezas mas similares \n",
    "que correspondan a cada cerveza que ha valorado ese usuario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_co_occurrance_matrix(min_rating=4):\n",
    "    \n",
    "    # LOS PARAMETROS DE VALORACION DE CERVEZAS POR ENCIMA DE min_rating\n",
    "    # CREAREMOS UN DICCIONARIO { 'user_id': array numpy['beer_id'_1, .., 'beer_id'_n], ...}\n",
    "    beersPerUser = (reviews_train[reviews_train['beeradvocate_score'] >= min_rating]\n",
    "                 .groupby('user_id')['beer_id']\n",
    "                 .apply(np.array)\n",
    "                 .to_dict()\n",
    "                )\n",
    "    \n",
    "    # CREAREMOS LA MATRIZ DE CO-OCURRENCIA\n",
    "    num_users = users_df['user_id'].max() + 1\n",
    "    num_beers = beers_df['beer_id'].max() + 1\n",
    "    coMatrix = np.zeros((num_users, num_beers))\n",
    "    for beers in beersPerUser.values():\n",
    "        for b in beers:\n",
    "            coMatrix[b, beers] += 1\n",
    "    return coMatrix, beersPerUser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOS PARAMETROS DE VALORACION DE CERVEZAS POR ENCIMA DE 3.50 COMIENZAN EL TRAMO DE LAS QUE FUERON CONSIDERADAS BUENAS CERVEZAS POR LOS USUARIOS: \n",
    "\n",
    "son las que interesan para recomendar otras buenas cervezas qu sean similares a ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coMatrix, beersPerUser = get_co_occurrance_matrix(3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrance_similarity(item_id, coocurrance, ntop=10):\n",
    "    \"\"\"\n",
    "    Devuelve las cervezas topN mas similares a una dada usando la matriz de co-ocurrencia\n",
    "    \n",
    "    :param item_id: id de la cerveza\n",
    "    :param cooccurrance: matriz de co-occurencia (numpy array)\n",
    "    :param ntop: numero de cervezas mas similares a la dada como item,_id que se van a devolver    \n",
    "    \"\"\"\n",
    "    similarItems = coocurrance[item_id, :]\n",
    "    # Devuelve indices de los items mas similares en orden descendente\n",
    "    mostSimilar = np.argsort(similarItems)[::-1]\n",
    "    # se quita el primer elemento que es la propia cerveza para la que busco las topN similares\n",
    "    mostSimilar = mostSimilar[1:ntop+1]\n",
    "    \n",
    "    # Puntuacion o Grado de Similaridad de cada item_id o cerveza mas similar\n",
    "    # similarItems[mostSimilar])\n",
    "    \n",
    "    # Devuelve un array numpy con indice (primera columna = item_id = beer_id) y,\n",
    "    # el Grado de Similaridad de esos items o cervezas mas similares (segunda columna = similaridad)\n",
    "    return np.stack((mostSimilar, similarItems[mostSimilar])).T\n",
    "    # Es mejor pero tambien valdria:\n",
    "    #return np.stack((mostSimilar, similarItems[mostSimilar]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Cerveza id = 49, 'Old Chub Scottish Style Ale', tiene esta matriz de co-ocurrencia:\n",
      "[[142. 452.]\n",
      " [223. 424.]\n",
      " [ 12. 401.]\n",
      " [294. 400.]\n",
      " [130. 399.]]\n"
     ]
    }
   ],
   "source": [
    "# Obtengamos las 5 cervezas mas similares a de la de beer_id = 49\n",
    "print(\"La Cerveza id = {0}, '{1}', tiene esta matriz de co-ocurrencia:\"\\\n",
    "      .format(49, beers_df[beers_df['beer_id'] == 49]['beer_name'].values.astype(str)[0]))\n",
    "print(co_occurrance_similarity(49, coMatrix, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la cerveza de id = \"49\", \"Old Chub Scottish Style Ale, Scotch Ale Wee Heavy (Strong Ales)\", \n",
      "las top-5 recommendaciones son:\n",
      "142 Old Rasputin Russian Imperial Stout, Russian Imperial Stout (Stouts) 452.0\n",
      "223 90 Minute IPA, American Imperial IPA (India Pale Ales) 424.0\n",
      "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales) 401.0\n",
      "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts) 400.0\n",
      "130 Stone Ruination IPA, American Imperial IPA (India Pale Ales) 399.0\n",
      "\n",
      "\n",
      "Para la cerveza de id = \"70\", \"Hocus Pocus, American Pale Wheat Ale (Wheat Beers)\", \n",
      "las top-5 recommendaciones son:\n",
      "351 Storm King Stout, Russian Imperial Stout (Stouts) 54.0\n",
      "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts) 51.0\n",
      "179 Arrogant Bastard Ale, American Strong Ale (Strong Ales) 48.0\n",
      "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales) 48.0\n",
      "136 Sierra Nevada Pale Ale, American Pale Ale (APA) (Pale Ales) 48.0\n",
      "\n",
      "\n",
      "Para la cerveza de id = \"300\", \"Sierra Nevada Tumbler Autumn Brown Ale, American Brown Ale (Brown Ales)\", \n",
      "las top-5 recommendaciones son:\n",
      "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales) 317.0\n",
      "142 Old Rasputin Russian Imperial Stout, Russian Imperial Stout (Stouts) 300.0\n",
      "266 Sierra Nevada Torpedo Extra IPA, American IPA (India Pale Ales) 296.0\n",
      "223 90 Minute IPA, American Imperial IPA (India Pale Ales) 278.0\n",
      "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts) 258.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Otros ejemplos\n",
    "queryBeerIds = [49, 70, 300]\n",
    "Ntop = 5\n",
    "for queryBeerId in queryBeerIds:\n",
    "    print('Para la cerveza de id = \"%s\", \"%s\", \\nlas top-%s recommendaciones son:' % \\\n",
    "          (queryBeerId, \\\n",
    "           get_beer_summary_by_id(beers_df, styles_df, queryBeerId), \\\n",
    "           Ntop))\n",
    "\n",
    "    similarBeers = co_occurrance_similarity(queryBeerId, coMatrix, Ntop)\n",
    "    for similarBeer in similarBeers:\n",
    "        print(int(similarBeer[0]), \\\n",
    "              get_beer_summary_by_id(beers_df, styles_df, similarBeer[0]), \\\n",
    "              similarBeer[1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las cervezas similares se observa que las cervezas mas populares, las que tienen mas votos y eran recomendadas por el recomendador mostRated, producen cierto sesgo en las recomendaciones de la matriz de coocurrencia ya que aparecen varias de ellas entre las primeras recomendaciones:\n",
    "\n",
    "223 90 Minute IPA, American Imperial IPA (India Pale Ales)\n",
    "\n",
    "142 Old Rasputin Russian Imperial Stout, Russian Imperial Stout (Stouts)\n",
    "\n",
    "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales)\n",
    "\n",
    "179 Arrogant Bastard Ale, American Strong Ale (Strong Ales)\n",
    "\n",
    "130 Stone Ruination IPA, American Imperial IPA (India Pale Ales)\n",
    "\n",
    "250 Two Hearted Ale, American IPA (India Pale Ales)\n",
    "\n",
    "136 Sierra Nevada Pale Ale, American Pale Ale (APA) (Pale Ales)\n",
    "\n",
    "134 Stone IPA (India Pale Ale), American IPA (India Pale Ales)\n",
    "\n",
    "312 Sierra Nevada Bigfoot Barleywine Style Ale, American Barleywine (Strong Ales)\n",
    "\n",
    "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHORA LA FUNCION PARA PODER HACER LAS RECOMENDACIONES\n",
    "def co_occurrance_recommendation(items_id, cooccurrance, ntop=10):\n",
    "    \"\"\"\n",
    "    Devuelve la lista de las ntop recomendaciones en base a la lista de items o cervezas \n",
    "    que ha valorado el usuario (historia de valoraciones del usuario)\n",
    "    \n",
    "    :param items_id: lista de items ids de las cervezas valoradas por el usuario\n",
    "    :param coocurrence: matriz de co-ocurrencia (array 2d numpy)\n",
    "    :param ntop: top-K items o cervezas que se devolveran    \n",
    "    \"\"\"\n",
    "\n",
    "    # Obtendremos las listas de items similares de cada item que ha valorado el usuario\n",
    "    # y guardamos cada lista en una fila\n",
    "    list_sim_items = np.vstack([co_occurrance_similarity(id_, cooccurrance, ntop) for id_ in items_id])\n",
    "    \n",
    "    # Agrupamos por cada beer_id y borramos duplicados teniendo en cuenta su frecuencia\n",
    "    largest_freq = pd.DataFrame(list_sim_items, columns=['id', 'freq']).groupby('id').agg(max).reset_index()\n",
    "    \n",
    "    # ordenamos por grado de similaridad en orden descendente\n",
    "    sorted_list = largest_freq.sort_values(by='freq', ascending=False)\n",
    "    \n",
    "    # obtenemos los ntop\n",
    "    out = sorted_list.values[:ntop, 0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>similar_beer_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1063.0, 294.0, 223.0, 142.0, 42.0, 136.0, 312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[142.0, 130.0, 134.0, 179.0, 225.0, 223.0, 12....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[223.0, 142.0, 130.0, 179.0, 134.0, 12.0, 312....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[223.0, 142.0, 130.0, 179.0, 134.0, 312.0, 12....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[223.0, 142.0, 130.0, 179.0, 134.0, 12.0, 312....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id                                   similar_beer_ids\n",
       "0        0  [1063.0, 294.0, 223.0, 142.0, 42.0, 136.0, 312...\n",
       "1        1  [142.0, 130.0, 134.0, 179.0, 225.0, 223.0, 12....\n",
       "2        2  [223.0, 142.0, 130.0, 179.0, 134.0, 12.0, 312....\n",
       "3        3  [223.0, 142.0, 130.0, 179.0, 134.0, 312.0, 12....\n",
       "4        4  [223.0, 142.0, 130.0, 179.0, 134.0, 12.0, 312...."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ntop = 50\n",
    "predictions = trainUsersGrouped['beer_id'].apply(lambda x: \n",
    "    co_occurrance_recommendation(x, coMatrix, Ntop)).reset_index()\\\n",
    "    .rename(columns={\"beer_id\":\"similar_beer_ids\", \"index\":\"beer_id\"})\n",
    "# index = beer_id que ha valorado un user_id dado, \n",
    "# beer_id = List of item_ids mas similares o Recommendations\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la cerveza de id = \"0\", \"Stone Old Guardian Barley Wine Style Ale 2006, American Barleywine (Strong Ales)\", \n",
      "las top-50 recommendaciones son:\n",
      "1063 Samuel Adams Black Lager, German Schwarzbier (Dark Lagers)\n",
      "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts)\n",
      "223 90 Minute IPA, American Imperial IPA (India Pale Ales)\n",
      "142 Old Rasputin Russian Imperial Stout, Russian Imperial Stout (Stouts)\n",
      "42 Samuel Adams Boston Lager, Vienna Lager (Dark Lagers)\n",
      "136 Sierra Nevada Pale Ale, American Pale Ale (APA) (Pale Ales)\n",
      "312 Sierra Nevada Bigfoot Barleywine Style Ale, American Barleywine (Strong Ales)\n",
      "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales)\n",
      "179 Arrogant Bastard Ale, American Strong Ale (Strong Ales)\n",
      "130 Stone Ruination IPA, American Imperial IPA (India Pale Ales)\n",
      ".... y hasta Ntop = 50 mas\n",
      "\n",
      "\n",
      "Para la cerveza de id = \"1\", \"Samuel Adams Brown Ale, English Brown Ale (Brown Ales)\", \n",
      "las top-50 recommendaciones son:\n",
      "142 Old Rasputin Russian Imperial Stout, Russian Imperial Stout (Stouts)\n",
      "130 Stone Ruination IPA, American Imperial IPA (India Pale Ales)\n",
      "134 Stone IPA (India Pale Ale), American IPA (India Pale Ales)\n",
      "179 Arrogant Bastard Ale, American Strong Ale (Strong Ales)\n",
      "225 60 Minute IPA, American IPA (India Pale Ales)\n",
      "223 90 Minute IPA, American Imperial IPA (India Pale Ales)\n",
      "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales)\n",
      "312 Sierra Nevada Bigfoot Barleywine Style Ale, American Barleywine (Strong Ales)\n",
      "250 Two Hearted Ale, American IPA (India Pale Ales)\n",
      "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts)\n",
      ".... y hasta Ntop = 50 mas\n",
      "\n",
      "\n",
      "Para la cerveza de id = \"2\", \"Hennepin (Farmhouse Saison), Belgian Saison (Pale Ales)\", \n",
      "las top-50 recommendaciones son:\n",
      "223 90 Minute IPA, American Imperial IPA (India Pale Ales)\n",
      "142 Old Rasputin Russian Imperial Stout, Russian Imperial Stout (Stouts)\n",
      "130 Stone Ruination IPA, American Imperial IPA (India Pale Ales)\n",
      "179 Arrogant Bastard Ale, American Strong Ale (Strong Ales)\n",
      "134 Stone IPA (India Pale Ale), American IPA (India Pale Ales)\n",
      "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales)\n",
      "312 Sierra Nevada Bigfoot Barleywine Style Ale, American Barleywine (Strong Ales)\n",
      "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts)\n",
      "250 Two Hearted Ale, American IPA (India Pale Ales)\n",
      "351 Storm King Stout, Russian Imperial Stout (Stouts)\n",
      ".... y hasta Ntop = 50 mas\n",
      "\n",
      "\n",
      "Para la cerveza de id = \"3\", \"Double Bag, German Altbier (Brown Ales)\", \n",
      "las top-50 recommendaciones son:\n",
      "223 90 Minute IPA, American Imperial IPA (India Pale Ales)\n",
      "142 Old Rasputin Russian Imperial Stout, Russian Imperial Stout (Stouts)\n",
      "130 Stone Ruination IPA, American Imperial IPA (India Pale Ales)\n",
      "179 Arrogant Bastard Ale, American Strong Ale (Strong Ales)\n",
      "134 Stone IPA (India Pale Ale), American IPA (India Pale Ales)\n",
      "312 Sierra Nevada Bigfoot Barleywine Style Ale, American Barleywine (Strong Ales)\n",
      "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales)\n",
      "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts)\n",
      "250 Two Hearted Ale, American IPA (India Pale Ales)\n",
      "351 Storm King Stout, Russian Imperial Stout (Stouts)\n",
      ".... y hasta Ntop = 50 mas\n",
      "\n",
      "\n",
      "Para la cerveza de id = \"4\", \"Berkshire Russian Imperial Stout, Russian Imperial Stout (Stouts)\", \n",
      "las top-50 recommendaciones son:\n",
      "223 90 Minute IPA, American Imperial IPA (India Pale Ales)\n",
      "142 Old Rasputin Russian Imperial Stout, Russian Imperial Stout (Stouts)\n",
      "130 Stone Ruination IPA, American Imperial IPA (India Pale Ales)\n",
      "179 Arrogant Bastard Ale, American Strong Ale (Strong Ales)\n",
      "134 Stone IPA (India Pale Ale), American IPA (India Pale Ales)\n",
      "12 Sierra Nevada Celebration Ale, American IPA (India Pale Ales)\n",
      "312 Sierra Nevada Bigfoot Barleywine Style Ale, American Barleywine (Strong Ales)\n",
      "294 Brooklyn Black Chocolate Stout, Russian Imperial Stout (Stouts)\n",
      "250 Two Hearted Ale, American IPA (India Pale Ales)\n",
      "351 Storm King Stout, Russian Imperial Stout (Stouts)\n",
      ".... y hasta Ntop = 50 mas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queryBeerIds = predictions.head()['beer_id']\n",
    "for queryBeerId in queryBeerIds:\n",
    "    print('Para la cerveza de id = \"%s\", \"%s\", \\nlas top-%s recommendaciones son:' % \\\n",
    "          (queryBeerId, \\\n",
    "           get_beer_summary_by_id(beers_df, styles_df, queryBeerId), \\\n",
    "           Ntop))\n",
    "\n",
    "    similarBeers = predictions[predictions['beer_id'] == queryBeerId]['similar_beer_ids'].tolist()[0]\n",
    "    counter = 0\n",
    "    for similarBeer in similarBeers:\n",
    "        counter += 1\n",
    "        print(int(similarBeer), \\\n",
    "              get_beer_summary_by_id(beers_df, styles_df, int(similarBeer)))\n",
    "        if counter == 10:\n",
    "            print('.... y hasta Ntop = 50 mas')\n",
    "            break\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las cervezas recomendadas tambien se observa que las cervezas mas populares, las que tienen mas votos y eran recomendadas por el recomendador mostRated, producen cierto sesgo en las recomendaciones de la matriz de coocurrencia aunque ahora al menos se recomienda una cerveza distinta de ellas entre las 10 primeras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MEDIDA Recall-----\n",
      "recall@5=0.038\n",
      "recall@10=0.050\n",
      "recall@20=0.069\n",
      "recall@50=0.123\n",
      "-----MEDIDA Map-----\n",
      "map@5=0.019\n",
      "map@10=0.016\n",
      "map@20=0.015\n",
      "map@50=0.015\n"
     ]
    }
   ],
   "source": [
    "# VAMOS A EVALUAR EL RECOMENDADOR POR MATRIZ DE CO-OCURRENCIA\n",
    "topk = [5, 10, 20, 50]\n",
    "predictions_ids = predictions['similar_beer_ids'].values\n",
    "m = Metrics(train_ids, test_ids, predictions_ids)\n",
    "print('-----MEDIDA Recall-----')\n",
    "_ = m.recall_at_n(topk)\n",
    "print('-----MEDIDA Map-----')\n",
    "_ = m.map_at_n(topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall@n de la Matriz de Co-ocurrencia es un poco mas baja que mostRated, muy similar.\n",
    "\n",
    "map@n igualmente tambien es un poco mas baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.- RECOMENDADOR DE FILTRADO COLABORATIVO TIPO ALS (Alternating Least Squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver:\n",
    "https://medium.com/datos-y-ciencia/intro-als-pyspark-7de7f3ba3b0a\n",
    "\n",
    "Es un algoritmo de factorización matricial con regularización que evita el sobreajuste del algoritmo SVD (Singular Value Decomposition) al aumentar su numero de dimensiones.\n",
    "\n",
    "The ALS algorithm aims to estimate two unknown matrices which, when multiplied together, yield the rating matrix.\n",
    "\n",
    "ALS se usa para calcular las matrices q_i y p_u mediante factorización de la matriz de interacciones usuarios-ítems con pesos que si se multiplican da como resultado la matriz de valoraciones estimada r_ui_estimada. \n",
    "\n",
    "La funcion de perdida (loss) aplicada que se optimizara con ALS es la suma de errores al cuadrado:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?\\underset{Q*&space;,&space;P*}{min}\\sum_{(u,i)\\epsilon&space;K&space;}(r_{ui}-P_u^TQ_i)^2&plus;\\lambda(\\left&space;\\|&space;Q_i&space;\\right&space;\\|^2&space;&plus;&space;\\left&space;\\|&space;P_u&space;\\right&space;\\|^2)$&space;&space;$\" title=\"\\underset{q* , p*}{min}\\sum_{(u,i)\\epsilon K }(r_{ui}-q_i^Tp_u)^2+\\lambda(\\left \\| q_i \\right \\|^2 + \\left \\| p_u \\right \\|^2)\" />\n",
    "\n",
    "<img alt=\"factorization\" src=https://miro.medium.com/max/1421/1*SVgAXmUZjBal1-NXAoB_fA.jpeg\n",
    "style=\"width: 600px\"/>\n",
    "<br clear=\"all\"/>\n",
    "\n",
    "ALS se basa en el hecho de que la optimización se aborda como dos problemas cuadráticos obtenidos fijando, de forma alternativa, los términos p_u y q_i, en principio desconocidos. Cuando todos los términos p_u han sido fijados, el sistema hace iteraciones para optimizar los términos q_i por mínimos cuadrados y despues realizara iteraciones fijando los términos q_i para optimizar los terminos p_u [Koren, Y., Bell, R., Volinsky, C., 2009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alsRmse(I,R,P,Q):\n",
    "    return np.sqrt(np.sum((I * (R - np.dot(P,Q.T)))**2)/len(R[R > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def iteration(user, fixed_vecs, counts, num_factors, reg_param, num_solve, verbose=False):\n",
    "    num_fixed = fixed_vecs.shape[0]\n",
    "    YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "    eye = np.eye(num_fixed)\n",
    "    lambda_eye = reg_param * np.eye(num_factors)\n",
    "    solve_vecs = np.zeros((num_solve, num_factors))\n",
    "\n",
    "    t = time.time()\n",
    "    for i in range(num_solve):\n",
    "        if user:\n",
    "            counts_i = counts[i]\n",
    "        else:\n",
    "            counts_i = counts[:, i].T\n",
    "        CuI = np.diag(counts_i)\n",
    "        pu = counts_i.copy()\n",
    "        pu[np.where(pu != 0)] = 1.0\n",
    "        YTCuIY = fixed_vecs.T.dot(CuI).dot(fixed_vecs)\n",
    "        YTCupu = fixed_vecs.T.dot(CuI + eye).dot(pu.T)\n",
    "        xu = np.linalg.solve(YTY + YTCuIY + lambda_eye, YTCupu)\n",
    "        solve_vecs[i] = xu\n",
    "        if verbose and i % 300 == 0:\n",
    "            print('Solved %i vecs in %d seconds' % (i, time.time() - t))\n",
    "            t = time.time()\n",
    "\n",
    "    return solve_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPROBAMOS EL RENDIMIENTO DE ALS DIBUJANDO UNA GRAFICA CON LOS ERRORES ENTRAIN Y EN TEST\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def check_als_performance(n_epochs, train_errors, test_errors):\n",
    "    plt.plot(range(n_epochs), train_errors, marker='o', label='Training Data');\n",
    "    plt.plot(range(n_epochs), test_errors, marker='v', label='Test Data');\n",
    "    plt.title('ALS-WR Learning Curve')\n",
    "    plt.xlabel('Number of Epochs');\n",
    "    plt.ylabel('RMSE');\n",
    "    plt.ylim(1, 5)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_ui_matrix(dfratings, training_flag=True, verbose=False):\n",
    "    # dfratings dataset de ratings de TRAINING o de TEST\n",
    "    # El valor de 'user_id' y 'beer_id' empiezan en cero\n",
    "    uMatrixTraining = np.zeros((users_df['user_id'].max()+1, \\\n",
    "                                beers_df['beer_id'].max()+1))\n",
    "    if training_flag:\n",
    "        print('INICIO Generacion Matriz r_ui de TRAINING')\n",
    "    else:\n",
    "        print('INICIO Generacion Matriz r_ui de TEST')\n",
    "    for row in dfratings.values[:,0:3]:\n",
    "        # Note user ids start at 1\n",
    "        user = int(row[0]) # row['user_id']\n",
    "        beer = int(row[1]) # row['beer_id']\n",
    "        rating = row[2] # row['beeradvocate_score']\n",
    "        if verbose:\n",
    "            print(user, beer, rating)\n",
    "        uMatrixTraining[user, beer] = rating\n",
    "\n",
    "    print('FINAL Generacion Matriz r_ui de TRAINING')\n",
    "\n",
    "    return uMatrixTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SI DEFINO EL RECOMENDADOR ALS en un metodo train_als_recommender me da error Memory Error.\n",
    "\n",
    "def train_als_recommender(r_ui_Training, r_ui_Test, num_iterations, num_factors, lambda_term, verbose)\n",
    "    ...\n",
    "    return user_vectors, item_vectors, train_errors, test_errors\n",
    "\n",
    "Voy a probar si meto todo el codigo en un solo bloque y solo cargolas variables que necesito para ALS a ver si no vuelve a fallar por Memory Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIO Generacion Matriz r_ui de TRAINING\n",
      "FINAL Generacion Matriz r_ui de TRAINING\n"
     ]
    }
   ],
   "source": [
    "r_ui_MatrixTraining = get_r_ui_matrix(reviews_train, True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30810, 6504)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30810, 6504)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r_ui_MatrixTraining.shape)\n",
    "users_df['user_id'].max()+1, beers_df['beer_id'].max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIO Generacion Matriz r_ui de TEST\n",
      "FINAL Generacion Matriz r_ui de TRAINING\n"
     ]
    }
   ],
   "source": [
    "r_ui_MatrixTesting = get_r_ui_matrix(reviews_test, False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30810, 6504)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30810, 6504)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r_ui_MatrixTesting.shape)\n",
    "users_df['user_id'].max()+1, beers_df['beer_id'].max()+1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intento entrenar un ALS para 30.810 user_ids x 6.504 bber_ids = 200.388.240, A LO MEJOR NECESITO PySpark para este modelo y estos DATASET de Ratings r_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c67b1071f297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnum_beers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeers_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beer_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnum_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_ui_MatrixTraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_ui_MatrixTraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#def train_als_recommender(r_ui_Training, r_ui_Test, \\\n",
    "#                          num_iterations=10, num_factors=50, lambda_term=0.2, verbose=True):\n",
    "    # r_ui_MatrixTraining matriz de ratings (user_id x beer_id) de TRAINING\n",
    "    # r_ui_MatrixTesting matriz de ratings (user_id x beer_id) de TEST\n",
    "    # num_iterations ES NUMERO DE ITERACIONES DE CALCULO DE OPTIMIZACIONES\n",
    "    # num_factors ES EL NUMERO DE FACTORES DE LAS MATRICES A CALCULAR p_u y q_i\n",
    "    # lambda_term ES EL TERMINO DE REGUILARIZACION PARA EVITAR EL OVERFITTING\n",
    "num_iterations=10\n",
    "#num_factors=50 <== HAY Memory Error\n",
    "num_factors=20\n",
    "lambda_term=0.2\n",
    "\n",
    "num_users = users_df['user_id'].max() + 1\n",
    "num_beers = beers_df['beer_id'].max() + 1\n",
    "num_pairs = reviews_train.shape[0]\n",
    "R = r_ui_MatrixTraining.copy()\n",
    "p = r_ui_MatrixTraining.copy()\n",
    "p[p > 0] = 1\n",
    "p[p == 0] = 0\n",
    "T = r_ui_MatrixTesting.copy()\n",
    "ptest = r_ui_MatrixTesting.copy()\n",
    "ptest[ptest > 0] = 1\n",
    "ptest[ptest == 0] = 0\n",
    "alpha = num_pairs / (num_users * num_beers)\n",
    "C = alpha * R\n",
    "user_vectors = np.random.normal(size=(num_users, num_factors))\n",
    "item_vectors = np.random.normal(size=(num_beers, num_factors))\n",
    "train_errors = []\n",
    "print(\"INICIO DE {0} INTERACIONES, {1} FACTORES Y REGULARIZACION LAMBDA {2}.\"\\\n",
    "    .format(num_iterations, num_factors, lambda_term))\n",
    "test_errors = []\n",
    "for i in range(num_iterations):\n",
    "    print('Calculando optimizaciones para user_vectors...')\n",
    "    user_vectors = iteration(True, item_vectors, C, num_factors, lambda_term, num_users)\n",
    "    print('Calculando optimizaciones para item_vectors...')\n",
    "    item_vectors = iteration(False, user_vectors, C, num_factors, lambda_term, num_beers)\n",
    "    print('iteracion %i finalizada' % (i + 1))\n",
    "\n",
    "    train_rmse = alsRmse(p, r_ui_MatrixTraining, user_vectors, item_vectors)\n",
    "    test_rmse = alsRmse(ptest, r_ui_MatrixTesting, user_vectors, item_vectors)\n",
    "    train_errors.append(train_rmse)\n",
    "    test_errors.append(test_rmse)\n",
    "    print(\"[Iteracion %d de %d] train error: %f, test error: %f\" \n",
    "        %(i+1, num_iterations, train_rmse, test_rmse))\n",
    "\n",
    "print(\"FINAL DE LAS INTERACIONES\")\n",
    "    \n",
    "    #return user_vectors, item_vectors, train_errors, test_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.- RECOMENDADOR DE FILTRADO COLABORATIVO TIPO SVD (Singular Value Decomposition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los modelos de Filtrado Colaborativo de Factorizacion de Matrices se intentan obtener los factores latentes (vectores) para poder modelizar las interacciones de los usuarios con los items que, a diferencia del la matriz de coocurrencia, los espaciones latentes son de menor tamaño (alrededor de 100 dimensiones) y se pueden usar para hacer las recomendaciones.\n",
    "\n",
    "## $$r_{u,i} \\approx {\\bf f}_u^T\\cdot{\\bf f}_i$$\n",
    "\n",
    "En el caso de SVD el objetivo es reducir la dimensionalidad del espacio de entrada: SVD es casi lo mismo que la Descomposicion Eigen o PCA (Principal Component Analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METRICA RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(prediction, ground_truth):\n",
    "    \"\"\"\n",
    "    Return the Root Mean Squared Error of the prediction\n",
    "    \n",
    "    :param prediction: Un array numpy de 2d con las recomendaciones (predicciones a aevaluar)\n",
    "    :param ground_truth: Un array numpy de 2d con valoraciones reales (del dataset TEST)\n",
    "    \n",
    "    :return the RMSE\n",
    "    \"\"\"\n",
    "    # Obtiene los indices de los elementos que no son cero dentro del dataset TEST\n",
    "    r, c = ground_truth.nonzero()\n",
    "    # Obtiene los elementos que no son cero dentro de las recomendaciones\n",
    "    p = prediction[r,c]\n",
    "    # Obtiene los elementos que no son cero dentro del dataset TEST\n",
    "    t = ground_truth[r,c]\n",
    "    return sqrt(np.mean(np.power(p-t, 2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20\n",
    "u, s, vt = svds(r_ui_MatrixTesting, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobaremos que las matrices generadas son ortogonales y tienen los tamaños adecuados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30810, 20)\n",
      "1.0453208183364293e-15\n"
     ]
    }
   ],
   "source": [
    "# U tiene 30810 user_ids x 20 = k factores, dimensiones correctas\n",
    "print(u.shape)\n",
    "# U es ortogonal\n",
    "print(rmse(np.dot(u.T,u), np.identity(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6504)\n",
      "1.0979426536895535e-15\n"
     ]
    }
   ],
   "source": [
    "# V tiene 20 = k factores x 6504 beers_ids, dimensiones correctas\n",
    "print(vt.shape)\n",
    "# V es ortogonal\n",
    "print(rmse(np.dot(vt,vt.T), np.identity(k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculo de las recomendaciones\n",
    "\n",
    "Calcularemos la matriz M (r_uid) de valoraciones (user_idx x beers_ids) segun esta formula:\n",
    "\n",
    "### $$M\\approx U\\mathrm{diag}(s)V^T$$\n",
    "\n",
    "El primer paso será crear la matriz diagonal de s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_diag_matrix = np.diag(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcularemos las recomendaciones o predicciones segun la formula anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdPredictions = np.dot(np.dot(u, s_diag_matrix), vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que las dimensiones son correctas comparandolas con la matriz r_ui de Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30810, 6504)\n",
      "(30810, 6504)\n"
     ]
    }
   ],
   "source": [
    "print(svdPredictions.shape)\n",
    "print(r_ui_MatrixTesting.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUAREMOS LAS PREDICCIONES Y EL MODELO SVD CON 20 DIMENSIONES LATENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD RMSE=3.550\n"
     ]
    }
   ],
   "source": [
    "print('SVD RMSE=%.3f' % rmse(svdPredictions, r_ui_MatrixTesting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Recall*****\n",
      "recall@5=0.012\n",
      "recall@10=0.015\n",
      "recall@20=0.019\n",
      "recall@50=0.029\n",
      "recall@100=0.040\n",
      "*****Map*****\n",
      "map@5=0.006\n",
      "map@10=0.005\n",
      "map@20=0.004\n",
      "map@50=0.004\n",
      "map@100=0.004\n"
     ]
    }
   ],
   "source": [
    "# recall para las primeras 200 predicciones de cada user_id\n",
    "svdPredictions_sorted = np.argsort(svdPredictions)[::-1]\n",
    "svdPredictions_sorted = svdPredictions_sorted[:, :200]\n",
    "test_ids = testUsersGrouped['beer_id'].values\n",
    "predicted_ids = svdPredictions_sorted\n",
    "topk = [5, 10, 20, 50, 100]\n",
    "m = Metrics(train_ids, test_ids, predicted_ids)\n",
    "print('*****Recall*****')\n",
    "_ = m.recall_at_n(topk)\n",
    "print('*****Map*****')\n",
    "_ = m.map_at_n(topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTA: Este es el tercer recomendador que he podido implementar porque la siguiente variante de SVD dió el mismo problema de memoria que ALS como se puede ver más abajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback Implicito vs Feedback Explicito\n",
    "\n",
    "El anterior algoritmo SVD intentan calcular o estimar la matriz de valoraciones (ratings).\n",
    "\n",
    "Sin embargo, es mas facil intentar modelizar la matriz de preferencias, o sea, si una cerveza le gusta o no a un  usuario.\n",
    "\n",
    "Necsitamos crear una matriz \"selector\" $I$ para la matriz de r_ui de valoraciones $R$ de forma que contenga 0 si no existia valoracion y 1 si existia valoracion para esa entrada y, se hara lo mismo para los datos de test.\n",
    "\n",
    "Convertiremos uMatrixTraining and uMatrixTesting en datos implicitos (I e I2 respectivamente) de forma que en estas nuesvas matrices si la valoracion es mayor que 3.5 (buena cerveza) entonces rellenaremos con 1 y si no rellenaremos con 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz Indice para los datos de training\n",
    "I = r_ui_MatrixTraining.copy()\n",
    "I[I > 3.50] = 1\n",
    "I[I == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz Indice para los datos de test\n",
    "I2 = r_ui_MatrixTesting.copy()\n",
    "I2[I2 > 3.50] = 1\n",
    "I2[I2 == 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos SVD con estas valoraciones implicitas y lo evaluamos con RMSE, recall@k y map@k, con Numero de Dimensiones Latentes k [10, 30, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Entrenando SVD con 50 dimensiones latentes\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-54038a79ff67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ms_diag_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# calculamos las recomendaciones (predicciones)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msvdPredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_diag_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVD RMSE=%.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvdPredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dim in [50]:\n",
    "    print(\"*\"*30)\n",
    "    print(\"Entrenando SVD con %s dimensiones latentes\" %dim)\n",
    "    # Entrenamos con SVD\n",
    "    u, s, vt = svds(I, dim)\n",
    "    s_diag_matrix = np.diag(s)\n",
    "    # calculamos las recomendaciones (predicciones)\n",
    "    svdPredictions = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "    print('SVD RMSE=%.3f' % rmse(svdPredictions, I2))\n",
    "    # recall\n",
    "    svdPredictions_sorted = np.argsort(svdPredictions)[::-1]\n",
    "    svdPredictions_sorted = svdPredictions_sorted[:, :200]\n",
    "    test_ids = testUsersGrouped['beer_id'].values\n",
    "    train_ids = trainUsersGrouped['beer_id'].values\n",
    "    predicted_ids = trainUsersGrouped['user_id'].apply(lambda i: svdPredictions_sorted[i-1]).values\n",
    "    topk = [10, 50, 100]\n",
    "    m = Metrics(train_ids, test_ids, predicted_ids)\n",
    "    print('*****Recall*****')\n",
    "    _ = m.recall_at_n(topk)\n",
    "    print('*****Map*****')\n",
    "    _ = m.map_at_n(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
